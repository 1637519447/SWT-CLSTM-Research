# SWT-CLSTM: Stationary Wavelet Transform Enhanced Convolutional LSTM for Cloud Resource Utilization Prediction

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)

## ğŸ“– Overview

SWT-CLSTM is a novel deep learning framework that combines **Stationary Wavelet Transform (SWT)**, **Convolutional Neural Networks (CNN)**, and **Long Short-Term Memory (LSTM)** networks for accurate cloud resource utilization prediction. The model integrates multi-scale temporal feature extraction with contrastive learning mechanisms to achieve superior performance in CPU and memory utilization forecasting.

### Key Features

- ğŸŒŠ **Multi-scale Decomposition**: Utilizes Stationary Wavelet Transform for comprehensive temporal pattern analysis
- ğŸ§  **Hybrid Architecture**: Combines CNN for spatial feature extraction and LSTM for temporal dependency modeling
- ğŸ”„ **Contrastive Learning**: Implements advanced data augmentation and contrastive loss for robust feature learning
- ğŸ“Š **Multi-dataset Support**: Validated on real-world datasets from Alibaba and Google cloud traces
- ğŸ¯ **Statistical Validation**: Comprehensive statistical significance testing with t-tests and Wilcoxon signed-rank tests
- âš¡ **GPU Acceleration**: Full CUDA support for efficient training and inference

## ğŸ—ï¸ Architecture

The SWT-CLSTM model consists of three main components:

1. **SWT Decomposition Layer**: Decomposes time series into multiple frequency components
2. **CNN-LSTM Hybrid Network**: 
   - Convolutional layers for local pattern extraction
   - Five-layer LSTM with decreasing hidden units (200â†’160â†’130â†’100â†’70)
3. **Contrastive Learning Module**: Enhances model robustness through data augmentation and InfoNCE loss

## ğŸ“Š Performance

Our extensive experiments demonstrate significant improvements over baseline models:

### CPU Utilization Prediction (Alibaba 30s dataset)
- **SWT-CLSTM**: 2.315Ã—10â»âµ MSE
- **Performance Improvement**: 300%-2845% over baseline models (LSTM, ARIMA, TFC, PatchTST, TimeMixerPlusPlus)

### Memory Utilization Prediction (Alibaba 30s dataset)
- **SWT-CLSTM**: 4.721Ã—10â»â· MSE
- **Performance Improvement**: 233%-12026% over baseline models

All improvements are statistically significant (p < 0.001) with large effect sizes (Cohen's d > 0.7).

## ğŸš€ Quick Start

### Prerequisites

```bash
Python >= 3.8
PyTorch >= 1.9.0
CUDA >= 11.0 (optional, for GPU acceleration)
```

### Installation

1. Clone the repository:
```bash
git clone https://github.com/1637519447/SWT-CLSTM-Research.git
cd SWT-CLSTM-Research
```

2. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install numpy pandas matplotlib scipy scikit-learn
pip install pywavelets joblib tqdm thop
```

### Usage

#### Basic Training

```bash
# Train on CPU utilization data
python CPUrate_SWT_CLSTM_improved.py

# Train on memory utilization data
python Mem_SWT_CLSTM_improved.py
```

#### Ablation Studies

```bash
# Run ablation experiments
python CPUrate_SWT-CLSTM-C.py    # Without CNN
python CPUrate_SWT-CLSTM-S.py    # Without SWT
python CPUrate_SWT-CLSTM-SG.py   # Without SG filter
python CPUrate_SWT-CLSTM-SC.py   # Without SWT and CNN
python CPUrate_SWT-CLSTM-SSC.py  # Without SWT, SG filter, and CNN
```

#### Baseline Comparisons

```bash
# Compare with baseline models
python CPUrate_compared_PatchTST.py
python CPUrate_compared_TFC.py
python CPUrate_compared_TimeMixer.py
python CPUrate_compared_SG-LSTM_improved.py
```

#### Statistical Analysis

```bash
# Run statistical significance tests
python statistical_significance_test.py

# Generate robustness analysis
python robustness_check_SWT_CLSTM.py
```

## ğŸ“ Project Structure

```
SWT-CLSTM-Research/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ .gitignore                          # Git ignore file
â”œâ”€â”€ 
â”œâ”€â”€ Core Models/
â”‚   â”œâ”€â”€ CPUrate_SWT_CLSTM_improved.py  # Main SWT-CLSTM implementation
â”‚   â”œâ”€â”€ Mem_SWT_CLSTM_improved.py      # Memory prediction variant
â”‚   â””â”€â”€ Multivariate_SWT_CLSTM.py      # Multivariate version
â”œâ”€â”€ 
â”œâ”€â”€ Ablation Studies/
â”‚   â”œâ”€â”€ Ablation/                       # Ablation experiment results
â”‚   â”œâ”€â”€ CPUrate_SWT-CLSTM-*.py         # Ablation variants
â”‚   â””â”€â”€ Mem_SWT-CLSTM-*.py             # Memory ablation variants
â”œâ”€â”€ 
â”œâ”€â”€ Baseline Models/
â”‚   â”œâ”€â”€ CPUrate_compared_*.py          # Baseline model implementations
â”‚   â”œâ”€â”€ Memrate_compared_*.py          # Memory baseline models
â”‚   â””â”€â”€ Arima_cor.py                   # ARIMA baseline
â”œâ”€â”€ 
â”œâ”€â”€ Data Processing/
â”‚   â”œâ”€â”€ alibaba_data_processor.py      # Alibaba dataset processor
â”‚   â”œâ”€â”€ google_cluster_data_processor.py # Google dataset processor
â”‚   â”œâ”€â”€ azure_data_processor.py        # Azure dataset processor
â”‚   â””â”€â”€ csv_data_cleaner.py            # Data cleaning utilities
â”œâ”€â”€ 
â”œâ”€â”€ Analysis & Visualization/
â”‚   â”œâ”€â”€ statistical_significance_test.py # Statistical testing
â”‚   â”œâ”€â”€ robustness_check_SWT_CLSTM.py   # Robustness analysis
â”‚   â”œâ”€â”€ visualize_distribution_shift_results.py # Distribution analysis
â”‚   â”œâ”€â”€ *_plot.py                       # Visualization scripts
â”‚   â””â”€â”€ images/                         # Generated plots and figures
â”œâ”€â”€ 
â”œâ”€â”€ Datasets/
â”‚   â”œâ”€â”€ Alibaba_*.csv                   # Alibaba cloud traces
â”‚   â”œâ”€â”€ Google_*.csv                    # Google cluster traces
â”‚   â”œâ”€â”€ Azure_*.csv                     # Azure cloud traces
â”‚   â”œâ”€â”€ Pre_data/                       # Preprocessed data
â”‚   â””â”€â”€ Compared_data/                  # Comparison results
â”œâ”€â”€ 
â””â”€â”€ Results/
    â”œâ”€â”€ *.json                          # Experimental results
    â”œâ”€â”€ *.txt                           # Analysis reports
    â””â”€â”€ *.csv                           # Statistical test results
```

## ğŸ”¬ Experimental Setup

### Datasets

1. **Alibaba Cloud Traces (30s intervals)**
   - Real-world production data from Alibaba cloud infrastructure
   - CPU and memory utilization metrics

2. **Google Cluster Traces (5m intervals)**
   - Large-scale cluster workload data from Google
   - Resource usage patterns from production clusters

3. **Azure Cloud Traces (5m intervals)**
   - Microsoft Azure cloud infrastructure data
   - Used for distribution shift analysis

### Evaluation Metrics

- **Mean Squared Error (MSE)**
- **Root Mean Squared Error (RMSE)**
- **Mean Absolute Error (MAE)**
- **RÂ² Score**
- **Step-wise RMSE** (for multi-step prediction analysis)

### Statistical Validation

- **Paired t-tests** for mean difference significance
- **Wilcoxon signed-rank tests** for non-parametric validation
- **Cohen's d** for effect size measurement
- **Confidence intervals** at 95% level

## ğŸ“ˆ Results and Analysis

### Model Complexity
- **Parameters**: ~2.1M trainable parameters
- **MACs**: ~847K multiply-accumulate operations
- **Training Time**: ~19s per epoch (GPU)
- **Inference Time**: <1ms per sample

### Ablation Study Results
| Variant | Component Removed | Performance Drop |
|---------|------------------|------------------|
| SWT-CLSTM-C | CNN | 15-25% |
| SWT-CLSTM-S | SWT | 20-35% |
| SWT-CLSTM-SG | SG Filter | 10-18% |
| SWT-CLSTM-SC | SWT + CNN | 35-50% |
| SWT-CLSTM-SSC | SWT + SG + CNN | 45-60% |

## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

<!-- ### Development Setup

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request -->



<!-- ## ğŸ“š Citation

If you use this code in your research, please cite our work:

```bibtex
@article{swt_clstm_2024,
  title={SWT-CLSTM: Stationary Wavelet Transform Enhanced Convolutional LSTM for Cloud Resource Utilization Prediction},
  author={[Author Names]},
  journal={[Journal Name]},
  year={2024},
  publisher={[Publisher]}
}
``` -->

## ğŸ™ Acknowledgments

- Alibaba Group for providing the cloud trace datasets
- Google for the cluster usage traces
- Microsoft Azure for the cloud infrastructure data
- The PyTorch team for the excellent deep learning framework

## ğŸ“ Contact

For questions and support, please open an issue in this repository or contact:

- **Email**: [1637519447@qq.com]
- **GitHub**: [@1637519447](https://github.com/1637519447)

---

**Note**: This research is conducted for academic purposes. Please ensure compliance with data usage policies when working with cloud trace datasets.